<!doctype html><html lang=en><meta charset=utf-8><meta name=viewport content="width=device-width,minimum-scale=1,initial-scale=1"><title>promql notes</title><script>(function(b,d,e,a,g){b[a]=b[a]||[],b[a].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var f=d.getElementsByTagName(e)[0],c=d.createElement(e),h=a!="dataLayer"?"&l="+a:"";c.async=!0,c.src="https://www.googletagmanager.com/gtm.js?id="+g+h,f.parentNode.insertBefore(c,f)})(window,document,"script","dataLayer","GTM-TLVN7D6")</script><link rel=canonical href=https://seankhliao.com/blog/12021-07-31-promql-notes/><link rel=manifest href=/manifest.json><meta name=theme-color content="#000000"><meta name=description content="who invented this... thing"><link rel=icon href=https://seankhliao.com/favicon.ico><link rel=icon href=https://seankhliao.com/static/icon.svg type=image/svg+xml sizes=any><link rel=apple-touch-icon href=https://seankhliao.com/static/icon-192.png><style>*{box-sizing:border-box}:root{background:#000;color:#eceff1;font:18px inconsolata,monospace}@font-face{font-family:inconsolata;font-style:normal;font-weight:400;font-display:swap;src:local("Inconsolata"),local("Inconsolata-Regular"),url(https://seankhliao.com/static/inconsolata-var.woff2)format("woff2-variations"),url(https://seankhliao.com/static/inconsolata-400.woff2)format("woff2")}@font-face{font-family:inconsolata;font-style:normal;font-weight:700;font-display:swap;src:local("Inconsolata Bold"),local("Inconsolata-Bold"),url(https://seankhliao.com/static/inconsolata-var.woff2)format("woff2-variations"),url(https://seankhliao.com/static/inconsolata-700.woff2)format("woff2")}@font-face{font-family:lora;font-style:normal;font-weight:400;font-display:swap;src:local("Lora"),local("Lora-Regular"),url(https://seankhliao.com/static/lora-var.woff2)format("woff2-variations"),url(https://seankhliao.com/static/lora-400.woff2)format("woff2")}@font-face{font-family:lora;font-style:normal;font-weight:700;font-display:swap;src:local("Lora Bold"),local("Lora-Bold"),url(https://seankhliao.com/static/lora-var.woff2)format("woff2-variations"),url(https://seankhliao.com/static/lora-700.woff2)format("woff2")}body{grid:20vh 60vh/1fr repeat(3,minmax(90px,280px))1fr;display:grid;gap:0 1em;margin:0;padding:1vmin;background:#000;color:#eceff1;font:18px inconsolata,monospace}body>*{grid-column:2/span 3}h1{font-size:4.5vmin;grid-area:1/4/span 1/span 2;margin:0;place-self:end}h2{color:#999;font-size:3.5vmin;grid-area:2/4/span 1/span 2;place-self:start end;text-align:right}hgroup{font:700 5vmin lora,serif;grid-area:1/1/span 2/span 2;margin:0;place-self:end start}hgroup a{display:grid;grid:repeat(2,10vmin)/repeat(8,10vmin);place-content:center center}hgroup *:nth-child(n+5){grid-row:2/span 1}footer,iframe,pre,table,picture{grid-column:1/span 5;margin:.25em -1vmin 2em}picture img{width:100%;margin:auto}h3,h4,picture{margin:25vh 0 .25em}h5,h6{margin:1.5em 0 .25em}h3{font-size:2.441em}h4{font-size:1.953em}h5{font-size:1.563em}h6{font-size:1.25em}p{line-height:1.5;margin:0 0 1em}footer{margin:10vh auto 3vh}a,a:visited{color:inherit;font-weight:700;text-decoration:underline 1px #707070}a:hover{color:#a06be0;transition:color .16s;text-decoration:underline 1px #a06be0}h1 a,h1 a:hover,h1 a:visited,hgroup a,hgroup a:hover,hgroup a:visited{color:inherit;text-decoration:none}ul{list-style:none;margin:0}ul>*{margin:.5em;line-height:1.5em}ul>li:before{content:"Â»";margin:0 1ch 0 -3ch;position:absolute}ol>*{line-height:1.75em}blockquote{margin:1em;padding:.25em 1em;border-left:1ch solid #999}code{background:#303030;font:1em inconsolata,monospace;padding:.1em}pre{background:#303030;overflow-x:scroll;padding:1em}pre::-webkit-scrollbar{display:none}pre code{padding:0}iframe{margin:auto}em{color:#a06be0;background-color:unset;font-style:normal;font-weight:700}time{color:#999}table{border-collapse:collapse;border-style:hidden}th,td{padding:.4em;text-align:left}th{font-weight:700;border-bottom:.2em solid #999}tr:nth-child(5n) td{border-bottom:.1em solid #999}tbody tr:hover{background:#404040}noscript iframe{height:0;width:0;display:none;visibility:hidden}</style><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TLVN7D6" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript><h1><a href=/blog/>b<em>log</em></a></h1><h2>12021-07-31</h2><hgroup><a href=/><span>S</span><span>E</span><span>A</span><span>N</span>
<em>K</em><em>.</em><em>H</em><em>.</em>
<span>L</span><span>I</span><span>A</span><span>O</span></a></hgroup><h3 id=-promql-><em>PromQL</em></h3><p><a href=https://prometheus.io/docs/prometheus/latest/querying/basics/>PromQL</a>,
the query language for <a href=https://prometheus.io/>Prometheus</a>.<p>It is... not as intuitive as one would hope for such a widely used
monitoring system.<h4 id=-aside--google-mql><em>aside:</em> Google MQL</h4><p>Google's <a href=https://cloud.google.com/monitoring/mql>Monitoring Query Language</a>
makes much more sense:
select metric, pipe it to alignment / aggregations, output result.
I honestly think it's worth the read to get a grasp on the data model
and how time series things work.<h4 id=-promql--concepts><em>promql</em> concepts</h4><p>Data is stored in <em>time series</em> uniquely identified by name + all labels,
with 1 data point per timestamp.<h5 id=-instant--vector><em>instant</em> vector</h5><p>Multiple time series together form a instant vector<pre><code># a plain metric query results in an instant vector
http_server_requests_total

# these can be narrowed down with label sectors
http_server_requests_total{host=&quot;seankhliao.com&quot;}


# example of values for 2 time series
time:               0  1  2  3  4  5  6  7  8  9 10
{host=&quot;a.example&quot;}: 1  1  1  2  4  9 11 11 12 12 20
{host=&quot;b.example&quot;}: 0  0  0  4  5  6  6  6  7  8  8
</code></pre><p>Time series in an instant vector can be aggregated through
<a href=https://prometheus.io/docs/prometheus/latest/querying/operators/#aggregation-operators>aggregation operators</a>.<h5 id=-range--vector><em>range</em> vector</h5><p>Like an instant vector but each timestamp
contains the values from that point + all points going back a set duration.
Most aggregations <a href=https://prometheus.io/docs/prometheus/latest/querying/functions/>functions</a>
that downsample data take these.<p>If it were any more consistent,
all the functions taking a range vector would be <code>&lt;aggregation>_over_time</code> like these:
<a href=https://prometheus.io/docs/prometheus/latest/querying/functions/#aggregation_over_time>aggregation_over_time</a>
Which collapses an range vector back to an instant vector
but doesn't aggregate across time series.<pre><code>http_server_requests_total[2m]

# lookback of 2 for the previous example
time:                 0       1       2       3       4       5       6       7       8       9      10
{host=&quot;a.example&quot;}: [1]   [1 1]   [1 1]   [1 2]   [2 4]   [4 9]  [9 11] [11 11] [11 12] [12 12] [12 20]
{host=&quot;b.example&quot;}: [0]   [0 0]   [0 0]   [0 4]   [4 5]   [5 6]   [6 6]   [6 6]   [6 7]   [7 8]   [8 8]
</code></pre><h5 id=-alignment-><em>alignment</em></h5><p>Note in the above,
there's nothing specifying how frequently to output a data point.
This is the <code>step</code> parameter in an api call
and is usally calculated automatically or specified separately.
Within a step, prometheus looks back up to 5 minutes to find a data point.
This can be problematic,
as your data points might get dropped (reasons why prometheus prefers counters over guages)
or misaligned with the source, leading some data points to appear more than others.<p><em>note:</em> make sure <code>rate()</code> or other <code>_over_time</code> ranges are larger than <code>step</code>.<h5 id=-subquery-><em>subquery</em></h5><p>background: <a href=https://www.robustperception.io/composing-range-vector-functions-in-promql>composing range vectors</a><p>Subqueries are confusing things,
they turn an instant query (not vector) into a range vector.<pre><code>rate(http_requests_total[5m])[30m:1m]
</code></pre><ul><li><p><code>rate(http_requests_total[5m])</code>:
For every input timestamp:
look back 5 min, calculate the rate,
output a single value.<li><p><code>[30m:]</code>:
Each input timestamp covers the last 30 min.<li><p><code>[...:1m]</code>: Evaluate every 1 min.</ul><p>So together:
For each input timestamp:
look back 30 min, every 1 min within that, look back 5 min and calculate the rate.
This results in a range vector where every timestamp contains a vector of 30 (30/1) values.<h5 id=-recording--rules><em>recording</em> rules</h5><p>When do you want to use these?
As alluded to above, mostly to precalculate <code>rate</code> on counter metrics,
ex: <a href=https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/kubernetes-prometheusRule.yaml>kube-prometheus rules</a>.<p>Note: guidance on <a href=https://prometheus.io/docs/practices/rules/>naming rules</a>: <code>level:metric:operations</code><footer><a href=https://seankhliao.com/>home</a>
|
<a href=https://seankhliao.com/blog/>blog</a>
|
<a href=https://github.com/seankhliao>github</a></footer>